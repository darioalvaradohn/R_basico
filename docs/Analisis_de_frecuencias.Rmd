---
title: "Análisis de frecuencias"
author: "MSc. Darío Alvarado"
output:
  html_document: default
  word_document: default
header-includes:
- \usepackage{float}
- \floatstyle{boxed}
- \restylefloat{figure}
---

<div style="display:flex; align-items:center;">
  <img src="Imagenes/HNBI_LOGO1.jpeg" alt="Texto alternativo de la imagen" style="width:100px; margin-left:20px;">
</div>

```{css, echo=FALSE}
pre code {
  word-wrap: normal !important;
  white-space: pre !important;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

#### Paquetes

```{r, message=FALSE, warning=FALSE}
library(DescTools)
library(rio)
library(gtsummary)
library(vcd)
```

<br>

### Contenido{.tabset .tabset-pills}

<br>

#### Chi-cuadrado

El **Chi-cuadrado** (\( X^2 \)) es una prueba estadística utilizada para analizar si existe una relación entre dos variables categóricas (<ins>pruebas de independencia</ins>) o si una distribución observada se ajusta a una distribución esperada (<ins>pruebas de bondad de ajuste</ins>).

<br>

La fórmula del Chi-cuadrado es la siguiente:

$$
X^2 = \Sigma \frac{(O_i-E_i)^2}{E_i}
$$

Donde:

- \(O_i\) = valores observados en la categoría \(i\)

- \(E_i\) = valores esperados en la categoría \(i\)

Cuando hay dos frecuencias en un grupo de datos comunmente se hace un **Chi-cuadrado** para ver si la diferencia entre los grupos es significativa.

Supongamos que realizamos una encuesta y le consultamos a 100 personas si fuman o no fuman. 

```{r}
x <- c("fumadores" = 54, "no fumadores" = 46) # tenemos que 54 personas de 100 (54%) son fumadores y 46 (46%) son no fumadores.
x
```

La función para ejecutar la prueba de Chi-cuadrado es `chisq.test()`.

```{r}
chisq.test(x)
```

Se interpreta el valor de p tomando como referencia el valor de alpha que por defecto es de 0.05. 

- Si **p < 0.05** = si hay diferencias estadísticamente significativas entre los dos grupos. 

- Si **p ≥ 0.05** = los grupos no presentan diferencias estadísticamente significativas.

<br>

Esta prueba es dependiente del tamaño de la muestra, por lo que al aumentar el tamaño de la muestra se consigue la significancia del valor de p.

```{r}
x <- c("fumadores" = 540, "no fumadores" = 460) # aquí tenemos que 540 personas de 1000 (54%) que son fumadoras y 460 (46%) que son no fumadoras.
```

```{r}
chisq.test(x)
```

Ahora el resultado si es estadísticamente significativo, tenemos la misma proporción (54% contra 46%), pero pasamos de encuestar 100 personas a 1000 personas.

<br>

Podemos verificar los valores esperados y los valores observados de la siguiente manera:
  
```{r}
chi <- chisq.test(x) # creamos un objeto con nuestra prueba de chi-cuadrado
```

```{r}
chi$expected # por defecto los valores esperados son del 50% para cada proporción (cuando solo tenemos dos opciones), H0 = no hay diferencias entre las proporciones.
```

```{r}
chi$observed # son los valores reales que obtuvimos mediante la encuesta
```

También podemos ver el estadístico de Chi-cuadrado que aparece en el resultado de la prueba:

```{r}
chi$statistic # El valor crítico de Chi-cuadrado para 1 grado de libertad y un nivel de significancia de 0.05 es 3.84, por encima de eso habrá significancia estadística, por debajo de eso no habrá significancia.
```

Podemos extraer los residuales:

```{r}
chi$residuals
```

Y también los residuales estandarizados:

```{r}
chi$stdres

# los residuales estandarizados son las diferencias entre los conteos observados y esperados, divididos por la raíz del conteo esperado. Estos residuales estandarizados se utilizan para detectar observaciones que son muy diferentes de lo que se esperaría bajo la hipótesis nula.

# Si los residuales estandarizados tienen valores entre -2 y 2, no difieren de los valores esperados. Si los residuales tienen valores inferiores a -2, los valores observados están por debajo de los valores esperados. Si los residuales tienen valores superiores a 2, los valores observados están por encima de los valores esperados. Valores inferiores a -2 y superiores a 2 influyen en la significancia estadística de la diferencia entre las proporciones.
```

<br>


En la vida real, no siempre esperaremos que cada proporción sea del 50%, por lo que podemos modificar el valor esperado por defecto:

```{r}
chiesp <- chisq.test(x, p = c(0.7, 0.3)) # con el argumento `p` indicamos la proporción que nosotros esperariamos (70% fumadores y 30% no fumadores) según conocimientos previos.

chiesp
```

_Nota: El valor de p solo indica si los valores observados son estadísticamente diferentes o no de los valores esperados, pero no nos indica la dirección de esa diferencia (menor o mayor)._

Podemos ver los valores esperados según las proporciones que especificamos:

```{r}
chiesp$expected
```

Los valores observados:

```{r}
chiesp$observed
```

Y los residuales estandarizados:

```{r}
chiesp$stdres
```

<br>

Para ver la **relación entre variables categóricas** utilizando el mismo ejemplo, podemos agregar la variable de sexo:

```{r}
tabla <- matrix(c(320, 100, 220, 360), nrow = 2, byrow = TRUE) # creamos una matriz de datos
colnames(tabla) <- c("Fumadores", "No Fumadores")
rownames(tabla) <- c("Hombres", "Mujeres")
tabla
```

```{r}
chisq.test(tabla)
```

Si el valor de p es mayor o igual que 0.05 indica que las categorías son independietes (no hay relación). En este caso, el valor de p es menor que 0.05, por lo que se puede concluir que existe una relación entre el sexo y el hábito de fumar.

<br>

[Volver arriba](Analisis_de_frecuencias.html)

[Inicio](index.html)

<br>

#### Estimación de parámetros

La estimación de parámetros permite **inferir** los valores de los parámetros desconocidos de una población a partir de una muestra de datos.
Para conocer las proporciones de cada grupo respecto al total de la muestra podemos utilizar la función `binom.test()` (para datos binomiales).

```{r}
binom.test(540, 1000) # indicamos el número de observaciones para el primer grupo (540) respecto al total de la muestra (1000)

# El resultado nos muestra un valor de p para la significancia estadística de esa proporción, al igual que en la prueba de Chi-cuadrado, el nivel de significancia por defecto es de 0.05. Además de eso, también se muestra el intervalo de confianza al 95% y el valor de la media de la proporción.
```

El 54% de las personas encuestadas tienen el hábito de fumar, y se puede decir con un 95% de confianza que la verdadera proporción está entre el 50.8 y el 57.1% (p = 0.01244).

<br>

```{r}
binom.test(460, 1000) # ahora indicamos el número de observaciones para el segundo grupo (460) respecto al total de la muestra (1000)
```

El 46% de las personas encuestadas son no fumadoras, y se puede decir con un 95% de confianza que la verdadera proporción está entre el 42.8 y el 49.1% (p = 0.01244).

<br>

Si queremos especificar un valor esperado diferente, podemos indicarlo con el argumento `p =` para definir la proporción esperada para cada grupo:

```{r}
prop.test(540, 1000, p = 0.7) # proporción esperada del 70% para los fumadores
```

```{r}
prop.test(460, 1000, p = 0.3) # proporción esperada del 30% para los no fumadores
```

<br>

También podemos estimar la diferencia (en proporción) entre los dos grupos con la función `BinomDiffCI()` del paquete `DescTools`

```{r}
BinomDiffCI(540, 1000, 460, 1000) # colocamos las observaciones de la primera proporcion (540 de 1000) y luego de la segunda proporcion (460 de 1000)
```

El resultado muestra que la diferencia es del 8% y se puede decir con un 95% de confianza que la verdadera diferencia entre los dos grupos está entre 3.6 y 12.3%

<br>

También se puede conocer la proporción cuando hay más de dos grupos (datos multinomiales) con la función `MultinomCI()` del paquete `DescTools`.

```{r}
x <- c("Hombres fumadores" = 320, "Mujeres fumadoras" = 220, "Hombres no fumadores" = 100, "Mujeres no fumadoras" = 360)
```

```{r}
MultinomCI(x)
```

El estimado es la proporción (%) para cada grupo, y también se muestra el intervalo de confianza al 95% para cada proporción.

<br>

[Volver arriba](Analisis_de_frecuencias.html)

[Inicio](index.html)

<br>

#### Tablas de contingencia

Las tablas de contingencia son matrices que muestran la distribución de frecuencias de las variables y son muy utilizadas cuando se realizan encuestas.



Para este ejercicio utilizaremos la base de datos de oncocercosis (seguera de río provocada por un nematodo).

```{r}
onco <- import("data/oncocercosis.xlsx")
head(onco)
```

Resuminos los datos en una tabla de contingencia con la función `table()`

```{r}
cont <- table(onco$mf, onco$area) # haremos nuestra tabla con las variables mf (personas infectadas vs no infectadas) y area (área de procedencia). 
cont
```

Esta es una tabla de contingencia de 2 x 2 similar a la que teníamos de fumadores y no fumadores de acuardo al sexo.

<br>

También se puede elaborar una tabla más compleja con la función `tbl_cross()` del paquete `gtsummary`.

```{r, message=FALSE, warning=FALSE}
cont2 <- tbl_cross(onco, mf, area, 
                   percent = "cell") # con este argumento indicamos que la tabla muestre las proporciones en cada celda.
cont2
```

<br>

También podemos representarlo de forma gráfica con la función `mosaic()` del paquete `vcd`

```{r}
mosaic(~ mf + area, data = onco, 
       shade = TRUE) # con `shade = TRUE` se colorean las celdas de acuerdo al valor de los residuales estandarizados.
```

Podemos decir que hay una relación entre la infección y el área de procedencia. La mayoría de personas infectadas provienen de Rainforest (valor mayor al esperado según la escala de color de los residuales estandarizados).

En este gráfico de mosaico se evalúa la igualdad de proporciones y la independencia de los datos.

**Igualdad de proporciones:** El análisis de esos datos mostró una diferencia significativa (p < 0.05) entre las proporciones de las categorías, evaluada con un Chi-cuadrado.

**Independencia de los datos:** El análisis mostró que las variables infección y procedencia están relacionadas.

Interpretación de la escala de color: 

- El gris representa los valores observados que están dentro de los valores esperados (residuales estandarizados entre -2 y 2).

- El azul representa los valores que están por encima de los valores esperados (residuales estandarizados mayores a 2). 

- El rosado representa los valores que están por debajo de los valores esperados (residuales estandarizados menores a -2).

Si hacemos una prueba de Chi-cuadrado de nuestra tabla tendremos lo siguiente:

```{r}
chicont <- chisq.test(cont)
chicont
```

```{r}
chicont$expected
```

```{r}
chicont$observed
```

```{r}
chicont$stdres

# Los residuales estandarizados que se pasan de -2 o 2 son los que provocan la significancia estadística.
```

<br>

Ahora un ejemplo del gráfico de mosaico con una tabla de contingencia más compleja:

```{r}
data("HairEyeColor")
HairEyeColor

# Esta es una tabla de contingencia de 8 x 4 dividida en 4 x 4 para masculino y 4 x 4 para femenino
```

```{r}
mosaic(HairEyeColor, shade = TRUE)

# Para poder exportar este tipo de gráficos debemos colocar el código que utilizamos en el panel de consola de R, de esta forma, el gráfico aparecerá en la pestaña `Plots` del panel inferior derecho, ahí podemos dar click en la opción `Export` y luego una de las tres opciones para exportarlo. En las tres opciones podremos modificar el alto y el ancho de la imagen (por si las etiquetas se traslapan en el tamaño por defecto).
```

<br>

[Volver arriba](Analisis_de_frecuencias.html)

[Inicio](index.html)

<br>
