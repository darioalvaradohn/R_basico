---
output: html_document
header-includes:
  - \usepackage{float}
  - \floatstyle{boxed}
  - \restylefloat{figure}
---

<div style="display:flex; align-items:center;">
  <h1 style="margin:0;">Pruebas de hipótesis</h1>
  <img src="Imagenes/HNBI_LOGO1.jpeg" alt="Texto alternativo de la imagen" style="width:100px; margin-left:20px;">
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Las pruebas de hipótesis evaluan la probabilidad asociada a la hipótesis nula (H0) de que no hay efecto o diferencia entre dos grupos (`grupo1` = `grupo2`). El valor de P obtenido refleja la probabilidad de rechazar la H0, pero no prueba que la hipótesis alternativa, de que si hay efecto o diferencia (`grupo1` ≠ `grupo2`), sea verdadera. 

### Contenido{.tabset .tabset-pills}

#### Prueba de T-Student (paramétrica)

La prueba de **T-Student** sirve para comprobar si hay diferencias entre dos grupos. Es una **prueba paramétrica**, por lo que los datos deben cumplir con el supuesto de normalidad de la varianza.

```{r, message=FALSE, warning=FALSE}
library(rio)
```

```{r}
datos <- import("data/medidas_personas.csv")
head(datos)
```

```{r}
sM <- subset(datos, sexo == "M")
sF <- subset(datos, sexo == "F")
```

```{r}
shapiro.test(sM$altura)
```

```{r}
shapiro.test(sF$altura)
```

```{r}
t.test(altura ~ sexo, data = datos)
```

El valor de P no tiene unidades y depende del tamaño de la muestra, para obtener un resultado estadísticamente significativo se debe aumentar el tamaño de la muestra.
La variabilidad de los datos también influye en el valor de P, a menor variabilidad en los datos, menor el valor de P, a mayor variabilidad en los datos, mayor el valor de P.
El valor de P es condiconal a que la hipotesis nula es verdadera.

#### Prueba de Wilcoxon (no paramétrica)

Cuando los datos no provienen de una muestra con distribución normal existen alternativas de estadística **no paramétrica** para analizar los datos. La alternativa no paramétrica a la T-Student es la **prueba de Wilcoxon**. Esta tiene el mismo principio pero no requiere que los datos provengan de una muestra con distribución normal.

```{r}
shapiro.test(datos$peso)
```

```{r}
wilcox.test(peso ~ sexo, data = datos)
```

#### Alternativa con estimación de parámetros

Otra forma de analizar si hay diferencias entre dos grupos sin tener que recurrir a la estadística no paramétrica o pruebas de hipótesis, es mediante la **estimación de parámetros**. Para esto se genera un **estimado de punto** y un **intervalo de confianza** (tamaño del efecto) en las unidades de la variable.

Podemos estimarlo con la función `meanCI` del paquete `interpretCI`:

```{r}
library(interpretCI)
```

```{r}
meanCI(datos, sexo, altura)
```

```{r}
meanCI(datos, sexo, peso)
```

