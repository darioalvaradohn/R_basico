---
title: "Pruebas de hipótesis"
author: "MSc. Darío Alvarado"
output: html_document
header-includes:
  - \usepackage{float}
  - \floatstyle{boxed}
  - \restylefloat{figure}
---

<div style="display:flex; align-items:center;">
 <img src="Imagenes/HNBI_LOGO1.jpeg" alt="Texto alternativo de la imagen" style="width:100px; margin-left:20px;">
</div>

```{css, echo=FALSE}
pre code {
  word-wrap: normal !important;
  white-space: pre !important;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

Las pruebas de hipótesis evaluan la probabilidad asociada a la hipótesis nula (\(H_0\)) de que no hay efecto o diferencia entre dos grupos (`grupo1` = `grupo2`). El valor de p obtenido refleja la probabilidad de rechazar la \(H_0\), pero no prueba que la hipótesis alternativa, de que si hay efecto o diferencia (`grupo1` ≠ `grupo2`), sea verdadera. 

<br>

#### Paquetes 

```{r, message=FALSE, warning=FALSE}
library(rio)
library(interpretCI)
library(dabestr)
```

<br>

### Contenido{.tabset .tabset-pills}

<br>

#### Datos

```{r}
datos <- import("data/medidas_personas.csv")
head(datos)
```

<br>

#### Prueba de T-Student

La prueba de **T-Student** sirve para comprobar si hay diferencias entre **dos grupos**. Es una **prueba paramétrica**, por lo que los datos deben cumplir con el supuesto de normalidad de la varianza.

Primero hacemos los subgrupos de datos:

```{r}
sM <- subset(datos, sexo == "M")
sF <- subset(datos, sexo == "F")
```

Evaluamos la normalidad de los datos:

```{r}
shapiro.test(sM$altura)
```

```{r}
shapiro.test(sF$altura)
```

Realizamos la prueta de T-Student

```{r}
Ttest <- t.test(altura ~ sexo, data = datos) # Se coloca primero la variable respuesta (dependiente) y después la variable predictora (independiente) que debe ser categórica, separadas por una `~`.
Ttest
```

- Si el valor de **p < 0.05**, Si hay diferencias estadísticamente significativas entre los grupos.

- Si el valor de **p ≥ 0.05**, No hay diferencias estadísticamente significativas entre los grupos.

El valor de p no tiene unidades y depende del tamaño de la muestra, para obtener un resultado estadísticamente significativo se debe aumentar el tamaño de la muestra.

La variabilidad de los datos también influye en el valor de p, a menor variabilidad en los datos, menor el valor de p, a mayor variabilidad en los datos, mayor el valor de p.

El valor de p es condiconal a que la hipotesis nula es verdadera.

<br>

La prueba de T-Student también puede utilizarse para comparar la media de un grupo contra un valor teórico: 

```{r}
t.test(datos$altura, mu = 160) # `mu` indica el valor teórico de la media o la diferencia entre medias
```

O la diferencia de las medias de dos grupos contra un valor teórico:

```{r}
t.test(altura ~ sexo, data = datos, mu = -15)
```

<br>

[Volver arriba](T-Student.html)

[Inicio](index.html)

<br>

#### Prueba de Wilcoxon (Mann-Whitney)

Cuando los datos no cumplen con los supuestos de normalidad y homogeneidad de la varianza, se deben aplicar métodos estadísticos **no paramétricos** para analizar los datos. 

La alternativa no paramétrica a la T-Student es la **prueba de Wilcoxon**, también conocida como **prueba de Mann-Whitney**. Esta tiene el mismo principio pero no requiere que los datos cumplan el supuesto de normalidad.

```{r}
shapiro.test(datos$peso)
```

```{r}
wilcox.test(peso ~ sexo, data = datos)
```

- Si el valor de **p < 0.05**, Si hay diferencias estadísticamente significativas entre los grupos.

- Si el valor de **p ≥ 0.05**, No hay diferencias estadísticamente significativas entre los grupos.

<br>

[Volver arriba](T-Student.html)

[Inicio](index.html)

<br>

#### Estimación de parámetros

Otra forma de analizar si hay diferencias entre dos grupos sin tener que recurrir a la estadística no paramétrica o pruebas de hipótesis, es mediante la **estimación de parámetros**. Para esto se genera un **estimado de punto** y un **intervalo de confianza** (tamaño del efecto) en las unidades de la variable.

Podemos estimarlo con la función `meanCI()` del paquete `interpretCI`:

```{r}
meanCI(datos, sexo, altura)
```

**Interpretación**: Se puede decir con un 95% de confianza que la altura de las personas de sexo masculino es 17.31 cm mayor que la de las personas de sexo femenino (IC95% = 12.31, 22.31 cm; p = 6.622e-10).

<br>

```{r}
meanCI(datos, sexo, peso)
```

**Interpretación**: Se puede decir con un 95% de confianza que el peso de las personas de sexo masculino es 18.16 kg mayor que el de las personas de sexo femenino (IC95% = 13.04, 23.28 cm; p = 6.01e-10).

<br>

[Volver arriba](T-Student.html)

[Inicio](index.html)

<br>

#### Gráfico

Para realizar un gráfico comparativo podemos utilizar funciones del paquete `dabestr`.

Primero cargamos los datos para realizar la comparación con la función `load()`:

```{r}
comp <- load(datos, #datos
             x = sexo, # var. predictora
             y = altura, # var. respuesta
             idx = c("M", "F")) # grupos
```

Después realizamos el contraste para estimar la diferencia entre las medias y el intervalo de confianza al 95% con la función `mean_diff()`:

```{r}
md <- mean_diff(comp)
md
```

Por último graficamos ese contraste con la función `dabest_plot()`:

```{r}
dabest_plot(md)
```

En este gráfico tenemos dos escalas, la de la izquierda es la dispersión de los datos, y la de la derecha es la diferencia entre los grupos (**Tamaño/magnitud del efecto**).

<br>

[Volver arriba](T-Student.html)

[Inicio](index.html)

<br>